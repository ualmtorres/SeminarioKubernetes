////
NO CAMBIAR!!
Codificación, idioma, tabla de contenidos, tipo de documento
////
:encoding: utf-8
:lang: es
:toc: right
:toc-title: Tabla de contenidos
:doctype: book
:imagesdir: ./images




////
Nombre y título del trabajo
////
# Kubernetes
Cloud-DI Team - Departamento de Informática. UAL

image::di.png[]

// NO CAMBIAR!! (Entrar en modo no numerado de apartados)
:numbered!: 

[abstract]
== Resumen
////
COLOCA A CONTINUACION EL RESUMEN
////

[IMPORTANT]
====
*TRABAJO EN CURSO*
====

////
COLOCA A CONTINUACION LOS OBJETIVOS
////
.Objetivos
* Conocer la importancia del uso de Kubernetes en el ciclo de vida de las aplicaciones actuales.
* Introducir los conceptos básicos de Kubernetes.
* Usar Minikube para el desarrollo y prueba en local.
* Usar `kubectl` para la administración básica de Kubernetes.
* Escalar aplicaciones.
* Realizar actualizaciones en caliente (_rolling updates_).
* Desplegar aplicaciones con archivos YAML.
* Aprender a usar Kubernetes Dashboard.
    
[TIP]
====
Disponibles los repositorios usados en este seminario:

* https://github.com/ualmtorres/json-producer[Código fuente de JSON Producer]
* https://github.com/ualmtorres/json-reader[Código fuente de JSON Reader]
* https://github.com/ualmtorres/jsonproducerreader[Archivos YAML de JSON Producer y Reader]
====
// Entrar en modo numerado de apartados
:numbered:

## Introducción

La adopción de Docker sigue creciendo de forma imparable y cada vez más organizaciones lo usan en producción. Por tanto, se hace necesario contar con una plataforma de orquestación que permita administrar y escalar los contenedores.

Supongamos que hemos comenzado a usar Docker y hemos hecho un despliegue de un par de servidores. De pronto, la aplicación comienza a tener un gran tráfico de entrada y hay que escalar a una gran cantidad de servidores para atender la demanda. Aquí es donde entra Kubernetes para hacer tareas del tipo _dónde debe ir un contenedor, cómo se monitorizan esos contenedores_ o _cómo se reinician cuando tengan un problema_.

## Conceptos básicos

Kubernetes es una plataforma de código abierto para despliegue automático, escalado y gestión de aplicaciones contenedorizadas. Kubernetes ofrece una abstracción en la que permite el despliegue de aplicaciones en un cluster sin pensar en las máquinas que lo soportan. 

### Cluster de Kubernetes

Un cluster de Kubernetes está formado por dos tipos de recursos:

* El *Master* coordina el cluster. Coordina todas las actividades del cluster como organizar las aplicaciones, mantener el estado deseado de las aplicaciones, escalado, despliegue de actualizaciones, y demás.
* Los *Nodos* son _workers_ que ejecutan las aplicaciones. Cada nodo contiene un agente denominado _Kubelet_ que gestiona el nodo y mantiene la comunicación con el Máster. El nodo también tiene herramientas para trabajar con contenedores, como Docker.

[NOTE]
====
Un cluster Kubernetes en producción debería tener al menos 3 nodos.
====

image::KubernetesCluster.svg[]

Al desplegar una aplicación en Kubernetes el Master inicia los contenedores de la aplicación. El máster organiza los contenedores para que se ejecuten en los nodos del cluster. Los nodos se comunican con el master usando la https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.15/#-strong-api-overview-strong-[API de Kubernetes]. La API es expuesta a través del nodo Master y es posible usarla directamente para intectuar con el cluster.

.Lista de pods usando la API de Kubernetes
====
[source, bash]
----

$ curl http://<kubernetes_home>/api/v1/namespaces/default/pods
----

[source, json]
----
{
  "kind": "PodList",
  "apiVersion": "v1",
  "metadata": {
    "selfLink": "/api/v1/namespaces/default/pods",
    "resourceVersion": "10803"
  },
  "items": [
    {
      "metadata": {
        "name": "hello-minikube-64c7df9db-ffwtn",
        "generateName": "hello-minikube-64c7df9db-",
        "namespace": "default",
        "selfLink": "/api/v1/namespaces/default/pods/hello-minikube-64c7df9db-ffwtn",
        "uid": "652c298a-6dc2-4aec-a72f-390669fed6d2",
        "resourceVersion": "10608",
        "creationTimestamp": "2019-07-08T18:02:23Z",
        "labels": {
          "pod-template-hash": "64c7df9db",
          "run": "hello-minikube"
        },
....
----
====

Los clusters de Kubernetes se pueden desplegar sobre máquinas físicas o virtuales. Para comenzar a practicar con Kubernetes o para tareas de desarrollo, https://github.com/kubernetes/minikube[Minikube] es una buena opción. En la sección <<Minikube>> se presenta más información sobre esta plataforma. Minikube está disponible para Windows, Linux y MacOS.

### Objetos de Kubernetes

Kubernetes ofrece una serie de objetos básicos y una serie de abstracciones de nivel superior llamadas Controladores. Los Controladores se basan en los objetos básicos y proporcionan funcionalidades adicionales sobre los objetos básicos

Los objetos básicos de Kubernetes son:

* Pod
* Service
* Volume
* Namespace

Los objetos de nivel superior o Controladores se basan en los objetos básicos y ofrecen funcionalidades adicionales sobre los objetos básicos:

* ReplicaSet
* Deployment
* StatefulSet
* DaemonSet
* Job

[[Minikube]]
## Minikube

* Minikube es una implementación ligera de Kubernetes que crea una máquina virtual localmente y despliega un cluster sencillo formado por un solo nodo.

* Minikube es una gran herramienta para el desarrollo de aplicaciones Kubernetes y permite características habituales como _LoadBalancer_, _NodePort_, volúmenes persistentes, _Ingress_, dashboard, reglas de acceso, y demás.

En la https://github.com/kubernetes/minikube[página de GitHub de Minikube] se encuentra información sobre el proyecto, https://kubernetes.io/docs/tasks/tools/install-minikube/[instalación] y otros temas de interés.

Una vez instalado, probaremos los comandos básicos:

* Iniciar un cluster: `minikube start` (La primera vez que ejecutemos este comando descargará la ISO de Minikube, que son unos 130 MB, y creará la máquina virtual correspondiente)

* Acceso al Dashboard de Kubernetes: `minikube dashboard`

* Una vez iniciado, se podrá interactuar con el cluster usando `kubectl` (que veremos en la sección <<kubectl el CLI para Kubernetes>>) como con cualquier cluster Kubernetes:

    - Iniciar un servidor: `kubectl run hello-minikube --image=k8s.gcr.io/echoserver:1.4 --port=8080`

    - Exponer un servicio como un _NodePort_: `kubectl expose deployment hello-minikube --type=NodePort`
    
    - Abrir el endpoint del servicio en el navegador: `minikube service hello-minikube`

+    
El servidor de ejemplo iniciado muestra información sobre el cliente en el que se está ejecutando y sobre las cabeceras. Dicho servidor es expuesto en el cluster de Kubernetes como un _NodePort_. El resultado tras mostrarlo con `minikube service hello-minikube` será algo similar al de la figura siguiente.

+
image::SampleKubernetesService.png[]

+
Si ahora abrimos el dashboard, se mostraría algo similar a lo de la figura siguiente. En la figura se observa cómo ha sido creado el Deployment `hello-minikube`.

+
image::KubernetesDashboard.png[]
    
* Iniciar un segundo cluster local: `minikube start -p cluster2`

* Detener el cluster local: `minikube stop`

* Eliminar el cluster local: `minikube delete`

## `kubectl` el CLI para Kubernetes

Para la interacción con un cluster local o remoto de Kubernetes mediante comandos se usa `kubectl`, un CLI sencillo que nos permitirá realizar tareas habituales como despliegues, escalar el cluster u obtener información sobre los servicios en ejecución. 

Consultar la https://kubernetes.io/es/docs/tasks/tools/install-kubectl/#instalar-kubectl[página oficial de instalación y configuración de `kubectl`]

Para interactuar con unos ejemplos sencillo con `kubectl` podemos

* Obtener información de la versión

* Obtener información del cluster

+
[source, bash]
----
$ kubectl cluster-info
Kubernetes master is running at https://192.168.99.100:8443
KubeDNS is running at https://192.168.99.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
----

* Obtener los nodos que forman el cluster

+
[source, bash]
----
$ kubectl get nodes
NAME       STATUS   ROLES    AGE     VERSION
minikube   Ready    master   3d23h   v1.15.0
----

* Otras operaciones de interés son: 
    - `kubectl describe <resource>` para obtener información detallada sobre un recurso.
    - `kubectl logs <pod>` para mostrar los logs de un contenedor en un pod.
    - `kubectl exec <pod> <command>` para ejecutar un comando en un contenedor de un pod.

## Componentes de Kubernetes en acción

### Deployments

Una configuración de Deployment pide a Kubernetes que cree y actualice las instancias de una aplicación. Tras crear el Deployment, el Master organiza las instancias de aplicación en los nodos disponibles del cluster.

image::KubernetesDeployment.svg[]

Una vez creadas las instancias de aplicación, el *Controlador de Deployment de Kubernetes* monitoriza continuamente las instancias. Si un nodo en el que está una instancia cae o es eliminado, el Controlador de Deployment de Kubernetes sustituye la instancia por otra instancia en otro nodo disponible del cluster.

Esta funcionalidad de _autocuración_ de las aplicaciones supone un cambio radical en la gestión de las aplicaciones. Esta característica de recuperación de fallos mediante la creación de nuevas instancias que reemplazan a las defectuosas o desaparecidas no existía antes de los orquestadores.

Al crear un Deployment se especifica la imagen del contenedor que usará la aplicación y el número de réplicas que se quieren mantener en ejecución. El número de réplicas se puede modificar en cualquier momento actualizando el Deployment.

#### Despliegue de una aplicación

Podemos ejecutar una aplicación con `kubectl run` indicando el nombre que se dará al Deployment y el nombre de la imagen (Docker) usada para la aplicación.

[source, bash]
----
$ kubectl run jsonproducer --image=ualmtorres/jsonproducer:v0 --port 80 <1>

deployment.apps/jsonproducer created
----
<1> El puerto hace referencia al puerto que usa la aplicación original para servir su contenido.

Esto ha hecho que el Master haya buscado un nodo para ejecutar la aplicación, haya programado la ejecución de la aplicación en ese nodo y haya configurado el cluster para programar la ejecución de otra instancia cuando sea necesario.

[NOTE]
====
Para imágenes que no estén en Docker Hub se pasa la URL completa del repositorio de imágenes.
====

Para obtener los Deployments disponibles

[source, bash]
----
$ kubectl get deployments

NAME           READY   UP-TO-DATE   AVAILABLE   AGE
jsonproducer   1/1     1            1           8s
----

Para poder acceder a la aplicación deberemos primero exponerla en el cluster de Kubernetes. Más adelante veremos los detalles. Por ahora, basta con ejecutar el comando siguiente, el cual creará un _servicio_ asociado a nuestro Deployment para poder acceder a la aplicación. 

[source, bash]
----
$ kubectl expose deployment jsonproducer --type=NodePort

service/jsonproducer exposed
----

Para ver la ejecución de la aplicación, pediremos a Minikube que nos muestre el _servicio_ con el comando

[source, bash]
----
$ minikube service jsonproducer
----

Esto abrirá un navegador y el resultado del servicio es un JSON similar a este:

[source, json]
----
{"nombre":"manolo"}
----


### Pods

Al crear el Deployment anterior, Kubernetes creó un Pod para ejecutar la instancia de la aplicación. Un Pod es una abstracción de Kubernetes que representa un grupo de uno o más contenedores de una aplicación y algunos recursos compartidos de esos contenedores (p.e. volúmenes, redes)

[NOTE]
====
Un ejemplo de pod con más de un contenedor lo encontramos en lo que se denominan _sidecars_. Ejemplos de sidecar los encontramos en aplicaciones que registran su actividad en un contenedor (sidecar) dentro del mismo pod y publican la actividad en una aplicación que monitoriza el cluster. Otro ejemplo de sidecar es el de un contenedor sidecar que proporciona un certificado SSL para comunicación https al contenedor de la aplicación.
====

Los contenedores de un pod comparten una IP y un espacio de puertos, y siempre van juntos y se despliegan juntos en un nodo.

image::KubernetesPod.svg[]

Los pods son la unidad atómica de Kubernetes. Al crear un despliegue en Kubernetes, el Deployment crea Pods con contenedores en su interior. Cada pod queda ligado a un nodo y sigue allí hasta que se finalice o se elimine. En caso de fallo del nodo se planifica la creación de sus pods en otros nodos disponibles del cluster.

### Nodos

Los pods se ejecutan en un Nodo. Un nodo es una máquina _worker_ (física o virtual) del cluster. Los nodos están gestionados por el Master. Un Nodo puede contener muchos pods.

image::KubernetesNode.svg[]

Cada Nodo ejecuta al menos:

* Kubelet, un proceso que se encarga de la comunicación entre el nodo y el Master. Gestiona los pods y los contenedores que se están ejecutando en el nodo.
* Un motor de contenedores, como Docker, que se encarga de la descarga de imágenes de un registro y de ejecutar la aplicación.

### Servicios

Se dice que en Kubernetes los pods son mortales. Cuando un nodo desaparece (bien por un error o por una desconexión), los contenedores que están en el nodo también se pierden. A continuación, un _ReplicaSet_ se encarga de devolver al cluster al estado deseado y organiza la creación de nuevos pods en otros nodos disponibles para mantener funcionando la aplicación. Las réplicas de los pods han de ser intercambiables y *aunque cada pod en el cluster tenga su propia IP única, Kubernetes reconcialiará los cambios entre los pods para que las aplicaciones sigan funcionando*.

Los servicios en Kubernetes son una abstracción que definen un conjunto lógico de pods y una política de acceso a ellos. Esto permite que haya un acoplamiento débil entre pods dependientes. De esta forma, las aplicaciones sólo usarán los nombres de los servicios y no las IP de los pods, ya que éstas nunca son fijas debido a que, por un lado, los pods se crean y se destruyen para mantener el número de réplicas deseado; y por otro lado, un pod puede ser sustituido por otro ante un problema y el nuevo pod tendrá una IP diferente.

Cada pod tiene una dirección IP única, pero esa IP no se expone fuera del cluster sin lo que se denomina un Servicio. Los servicios pemiten que las aplicaciones reciban tráfico. En función del ámbito de la exposición del servicio tenemos:

* ClusterIP: El servicio recibe una IP interna a nivel de cluster y hace que el servicio sólo sea accesible a nivel de cluster.
* NodePort: Expone el servicio fuera del cluster concatenando la IP del nodo en el que está el pod y un número de puerto entre 30000 y 32767, que es el mismo en todos los nodos
* LoadBalancer: Crea en cloud, si es posible, un balanceador externo con una IP externa asignada.
* ExternalName: Expone el servicio usando un nombre arbitrario (especificado en `externalName`)

image::KubernetesService.svg[]

Los servicios enrutan el tráfico entre los pods proporcionando una abstracción que permite que los pod mueran y se repliquen sin impactar en la aplicación. El descubrimiento y enrutado entre pods dependientes (p.e. frontend y backend) son gestionados por los Servicios.

Los servicios agrupan a sus pods usando etiquetas y selectores. Las etiquetas son pares clave-valor y tienen usos muy variados:

* Diferenciar entre objetos de desarrollo, prueba y producción
* Distinguir entre versiones

image::KubernetesLabels.svg[]

En la figura se observa cómo el selector de etiquetas usado en los Deployment sirve para agrupar los pods que conforman un servicio, ya que cada pod contiene la misma etiqueta usada en el selector del Deployment al que pertenece.

Las etiquetas se pueden configurar durante la creación o en cualquier momento posterior.

#### Ejemplo. Creación de un servicio

Anteriormente, en la sección <<Despliegue de una aplicación>> creamos una aplicación de ejemplo que generaba un JSON de prueba. A modo de recordatorio, hicimos lo siguiente:

1. Crear un Deployment a partir de la imagen `ualmtorres/jsonproducer:v0` de Docker Hub con el comando 

+
[source, bash]
----
$ kubectl run jsonproducer --image=ualmtorres/jsonproducer:v0 --port 80
----

+
Podemos consultar el Deployment existente con el comando siguiente. Si por cualquier motivo no se dispone del Deployment, basta con ejecutar el comando anterior para crearlo.

+
[source, json]
----
$ kubectl get deployments
NAME           READY   UP-TO-DATE   AVAILABLE   AGE
jsonproducer   1/1     1            1           17m
----

+
Este Deployment habrá creado un pod que estará ejecutando la aplicación disponible de la imagen utilizada. Podemos ver los pods disponibles con el comando 

+
[source, bash]
----
$ kubectl get pods
NAME                            READY   STATUS    RESTARTS   AGE
jsonproducer-7769d76894-2nzt2   1/1     Running   0          23m
----

2. Crear un servicio para poder exponer la aplicación al exterior. Concretamente usamos un servicio de tipo NodePort, lo que nos sirve la aplicación concatenando la IP del nodo donde está el pod y un puerto aleatorio. El servicio lo creamos con  

+ 
[source, bash]
----
$ kubectl expose deployment jsonproducer --type=NodePort
----

+
Podemos consultar el servicio existente con el comando siguiente. Si por cualquier motivo no se dispone del servicio, basta con ejecutar el comando anterior para crearlo.

+
[source, bash]
----
$ kubectl get services
NAME           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
jsonproducer   NodePort    10.99.116.165   <none>        80:30737/TCP   25m <1>
kubernetes     ClusterIP   10.96.0.1       <none>        443/TCP        34d <2>
----
<1> Este es nuestro servicio. En el caso del tutorial, el puerto aleatorio asignado es el 30737
<2> Servicio `kubernetes` creado de forma predetermianda al iniciarse Minikube

+
Podemos acceder el servicio creado con

+
[source, bash]
----
$ minikube service jsonproducer
----

+
image::KubernetesRunningService.png[]

+
Si queremos consultar la información del servicio creado usaremos la opción `describe` de `kubectl` 

+
[source, bash]
----
$ kubectl describe services jsonproducer <1>

Name:                     jsonproducer
Namespace:                default
Labels:                   run=jsonproducer <2>
Annotations:              <none>
Selector:                 run=jsonproducer
Type:                     NodePort
IP:                       10.99.116.165
Port:                     <unset>  80/TCP
TargetPort:               80/TCP
NodePort:                 <unset>  30737/TCP
Endpoints:                172.17.0.5:80
Session Affinity:         None
External Traffic Policy:  Cluster
Events:                   <none>
----
<1> Pasamos el nombre de nuestro servicio como parámetro
<2> Etiqueta añadida de forma predeterminada

+
Si ahora consultamos la información del pod de la aplicación veremos que coincide la etiqueta. Recordemos que al introducir el concepto de Servicio se indicó que era una abstracción para agrupar pods y que utilizaba etiquetas para poder reunirlos. He aquí la correspondencia entre la etiqueta del servicio y la etiqueta de los pods del servicio.

[source, bash]
----
$ kubectl get pods <1> 

NAME                            READY   STATUS    RESTARTS   AGE
jsonproducer-7769d76894-2nzt2   1/1     Running   0          49m

$ kubectl describe pods jsonproducer-7769d76894-2nzt2 <2>

Name:               jsonproducer-7769d76894-2nzt2
Namespace:          default
Priority:           0
PriorityClassName:  <none>
Node:               minikube/10.0.2.15
Start Time:         Mon, 15 Jul 2019 18:56:20 +0200
Labels:             pod-template-hash=7769d76894
                    run=jsonproducer <3>
Annotations:        <none>
Status:             Running
IP:                 172.17.0.5
Controlled By:      ReplicaSet/jsonproducer-7769d76894 <4>
Containers:
  jsonproducer:
    Container ID:   docker://52e290262984a94da4dd89102b93d80f59c0c4310c303dac67b02884d73fb545
    Image:          ualmtorres/jsonproducer:v0 <5>
...
----
<1> Obtener primero los pods disponibles para poder acceder al pod deseado
<2> Obtener información del pod
<3> Etiqueta coincidente con el selector (etiqueta) del Deployment
<4> ReplicaSet encargado de mantener el número de pods deseados para el Deployment
<5> Imagen base usada para crear el único contenedor de este pod

## Escalado de una aplicación

Hasta ahora hemos creado un Deployment que posteriomente ha sido expuesto mediante un Servicio. Como no indicamos número de réplicas, el Deployment creó sólo un Pod para ejecutar la aplicación. Si la demanda aumenta quizá puede llegar a ser necesario aumentar el número de pods de la aplicación. Esto es lo que se conoce como escalado y hace referencia al número de réplicas en un Deployment.

[NOTE]
====
Para escalar un Deployment durante la creación se usa el parámetro `--replicas=<numero-de-replicas>`.
====

Al escalar una aplicación se crearán nuevos pods en los nodos con recursos disponibles e irá aumentando hasta llegar al número de pods deseados. La ejecución de varias instancias trae consigo la distribución del tráfico entre todos los pods del Deployment. De esta tarea se encarga un balanceador de carga que integra el propio Servicio.

[NOTE]
====
Escalar a 0 terminará todos los pods de un Deployment.
====

Una vez que entramos en la dinámica de tener varias instancias de la misma aplicación, se pueden tener actualizaciones en caliente (_rolling updates_) sin suspensión del servicio. Esto lo veremos en la sección <<Actualización de aplicaciones>>.

### Ejemplo de escalado de una aplicación

En primer lugar veremos cuáles eran las condiciones del despliegue de ejemplo que estamos usando.

[source, bash]
----
$ kubectl get deployments

NAME           READY   UP-TO-DATE   AVAILABLE   AGE
jsonproducer   1/1     1            1           68m
----

* `READY` indica el ratio entre los pods deseados y los que están en ejecución.
* `UP-TO-DATE` indica el número de réplicas que están actualizadas para alcanzar el estado deseado.
* `AVAILABLE` indica el número de réplicas disponibles actualmente para los usuarios.

El comando siguiente escala a 4 réplicas el despliegue de ejemplo (`jsonproducer`)

[source, bash]
----
$ kubectl scale deployments jsonproducer --replicas=4

deployment.extensions/jsonproducer scaled
----

Unos instantes después podremos comprobar que el Deployment ya ha alcanzado el estado deseado.

[source, bash]
----
$ kubectl get deployments

NAME           READY   UP-TO-DATE   AVAILABLE   AGE
jsonproducer   4/4     4            4           73m
----

La aplicación sigue disponible sin ningún cambio para el usuario final. Sin embargo, ahora hay 4 réplicas cuyo tráfico es gestionado por un balanceador de carga asociado al servicio.

image::KubernetesRunningService.png[]

La información de las réplicas la podemos obtener consultando el número de pods con el comando siguiente:

[source, bash]
----
$ kubectl get pods

NAME                            READY   STATUS    RESTARTS   AGE
jsonproducer-7769d76894-2nzt2   1/1     Running   0          74m
jsonproducer-7769d76894-9xdqw   1/1     Running   0          38s
jsonproducer-7769d76894-nhtl4   1/1     Running   0          38s
jsonproducer-7769d76894-qbvzd   1/1     Running   0          38s
----

Si ahora por cualquier motivo dejase de estar disponible alguno de los nodos en los que se encuentra desplegados los pods de la apliación, o bien dejase de funcionar alguno de los pods, el Controlador de Deployment de Kubernetes se encargaría de organizar la creación de nuevos pods para volver a alcanzar el estado deseado, en nuestro caso 4 réplicas.

Probemos esta funcionalidad eliminando el último pod y comprobando como Kubernetes organiza inmediatamente la creación de otro pod que lo sustituya.

[source, bash]
----
$ kubectl delete pods jsonproducer-7769d76894-qbvzd
pod "jsonproducer-7769d76894-qbvzd" deleted

$ kubectl get pods
NAME                            READY   STATUS    RESTARTS   AGE
jsonproducer-7769d76894-2nzt2   1/1     Running   0          85m
jsonproducer-7769d76894-9xdqw   1/1     Running   0          12m
jsonproducer-7769d76894-gh7qk   1/1     Running   0          3s <1>
jsonproducer-7769d76894-nhtl4   1/1     Running   0          12m
----
<1> Pod que sustituye al pod eliminado creado automáticamente para mantener el número de réplicas a 4

Por último, si ahora queremos reducir el número de réplicas a 2 bastará con volver a indicarlo al Deployment en el parámetro `replicas` y este será el nuevo estado a alcanzar.

[source, bash]
----
$ kubectl scale deployments jsonproducer --replicas=2
deployment.extensions/jsonproducer scaled

$ kubectl get pods
NAME                            READY   STATUS    RESTARTS   AGE
jsonproducer-7769d76894-2nzt2   1/1     Running   0          92m
jsonproducer-7769d76894-9xdqw   1/1     Running   0          18m
----

## Actualización de aplicaciones

Para poder realizar actualizaciones sin tener que suspender el servicio mientras se realiza la actualización, Kubernetes proporciona las _rolling updates_, que van actualizando los pods con la nueva versión de la aplicación.

De forma predeterminada, el número de pods que pueden estar no disponibles durante una actualización es 1, aunque esta opción es configurable, ya sea mediante cantidad o porcentaje de pods no disponibles durante la actualización. Además, es posible volver a una versión anterior.

Al igual que ocurre al escalar las aplicaciones, si el Despliegue está expuesto, el Servicio balancerá el tráfico sólo a los pods que estén disponibles durante la actualización.

A continuación se muestra cómo actualizar el Deployment de ejemplo `jsonproducer` con nuevo Deployment con el mismo nombre y una versión de la imagen. 

[source, bash]
----
$ kubectl set image deployments jsonproducer jsonproducer=ualmtorres/jsonproducer:v1
----

Al realizar la actualización de la imagen del Deployment, Kubernetes tendrá que descargar la nueva imagen y organizar la creación de los pods en los nodos con recursos disponibles. Mientras se realiza la actualización podremos ver que hay nodos que se están terminando, otros que se están creando y otros que están disponibles.

[source, bash]
----
$ kubectl get pods
NAME                            READY   STATUS              RESTARTS   AGE
jsonproducer-7769d76894-fr7cz   1/1     Running             0          25s
jsonproducer-7769d76894-hfpr7   1/1     Terminating         0          24s
jsonproducer-c76c87f-jwhxq      0/1     ContainerCreating   0          0s
jsonproducer-c76c87f-tmbkk      1/1     Running             0          1s
----

Tras unos instantes, la aplicación dejará de servir la versión anterior de la aplicación y comenzará a servir la nueva versión. La nueva versión de la aplicación sirve `Manolo Torres` en lugar de `manolo` en el JSON.

image::KubernetesUpdateImage.png[]

Para deshacer una actualización de una aplicación volviendo a la versión anterior haremos un `rollout undo`. El comando siguiente devuelve a la aplicación a la versión anterior

[source, bash]
----
$ kubectl rollout undo deployments jsonproducer
deployment.extensions/jsonproducer rolled back
----

Tras este comando, el Controlador de Deployment de Kubernetes irá reemplanzando los pods hasta alcanzar el estado deseado. A continuación se ve el estado intermedio mientras se vuelve a la versión anterior.

[source, bash]
----
$ kubectl get pods 
NAME                            READY   STATUS        RESTARTS   AGE
jsonproducer-7769d76894-m22sv   1/1     Running       0          2s
jsonproducer-7769d76894-v6hfv   1/1     Running       0          4s
jsonproducer-c76c87f-jwhxq      0/1     Terminating   0          14m
jsonproducer-c76c87f-tmbkk      0/1     Terminating   0          14m
----

Tras unos instantes, se alcanzará el estado deseado

[source, bash]
----
Caligari:~ manolo$ kubectl get pods
NAME                            READY   STATUS    RESTARTS   AGE
jsonproducer-7769d76894-m22sv   1/1     Running   0          8s
jsonproducer-7769d76894-v6hfv   1/1     Running   0          10s
----

Y la aplicación volverá a mostrar el contenido anterior.

image::KubernetesRunningService.png[]

## Despliegue de aplicaciones mediante archivos YAML

Hasta ahora, las interacción con Kubernetes la hemos hecho sobre la marcha, creando despliegues, servicios, escalado de aplicaciones y demás. Sin embargo, esta no es la forma habitual. Esta forma de uso de Kubernetes está más orientada a la creación de tareas puntuales. En cambio, cuando se trata de operaciones que queremos que sean repetibles, se suelen crear archivos YAML especificando el objeto que se quiere crear en Kubernetes (espacio de nombres, despliegue, servicio, ...). Una vez creados estos archivos, se usará `kubectl` para cargarlos/desplegarlos en Kubernetes.

[NOTE]
====
El uso de archivos para despliegues Kubernetes nos permitirá someter nuestro proyecto a control de versiones y poder distribuirlo fácilmente.
====

Para ilustrar el despliegue de una aplicación mediante archivos YAML vamos a desplegar una aplicación de ejemplo que consuma del servicio `jsonproducer` creado anteriormente. Este ejemplo es una versión muy sencilla de un entorno frontend-backend con un funcionamiento independiente lo que además de desacoplar la presetación del backendo, desde el punto de vista de la escalabilidad, permite un escalado independiente del backend y frontend.

### Creación del archivo de Deployment 

Vamos a crear un archivo de Deployment denominado `json-reader-deployment.yaml`. Este archivo básicamente contiene entre otros el nombre de despliegue, la etiqueta usada para agrupar los pods del servicio, número de réplicas y la imagen usada para crear el contenedor de cada pod.

[source, yaml]
----
apiVersion: extensions/v1beta1
kind: Deployment <1>
metadata:
  name: jsonreader <2>
  namespace: default <3>
  labels:
    app: jsonreader <4>
spec:
  revisionHistoryLimit: 2 <5>
  strategy:
    type: RollingUpdate <6>
  replicas: 2 <7>
  template:
    metadata:
      labels:
        app: jsonreader
    spec:
      containers:
      - image: ualmtorres/jsonreader:latest <8>
        name: jsonreader <9>
        ports:
        - name: http
          containerPort: 80 <10>
----
<1> Tipo de recurso a desplegar
<2> Nombre del despliegue
<3> Namespace de despliegue
<4> Selector usado para agrupar a los pods del servicio asociado
<5> Número de versiones almacenadas para poder deshacer despliegues fallidos
<6> Tipo de estrategia de actualización
<7> Número de réplicas del despliegue
<8> Imagen base para los contenedores de la aplicación
<9> Prefijo usado para los pods 
<10> Puerto por el que la aplicación sirve originalmente sus datos

El despliegue se realiza con `kubectl` con el comando siguiente

[source, bash]
----
$ kubectl create -f json-reader-deployment.yaml
----

Una vez creado el despliegue, se descargará la imagen y se pasarán a crear los dos pods indicados para este despliegue. Podemos ver los pods creados con el comando siguiente comprobando que efectivamente se creado los dos pods `jsonreader` que exigía el despliegue.

[source, bash]
----
$ kubectl get pods
NAME                            READY   STATUS    RESTARTS   AGE
jsonproducer-7769d76894-ss5qh   1/1     Running   0          106s
jsonreader-86699d9f94-khfzh     1/1     Running   0          28s
jsonreader-86699d9f94-lrvpt     1/1     Running   0          28s
----

### Creación del archivo de Servicio

Vamos a crear un archivo de Servicio denominado `json-reader-service.yaml`. Este archivo básicamente contiene entre otros el nombre de despliegue, la etiqueta usada para agrupar los pods del servicio, número de réplicas y la imagen usada para crear el contenedor de cada pod.

[source, yaml]
----
apiVersion: v1
kind: Service <1>
metadata:
  name: jsonreader <2>
  namespace: default <3>
spec:
  type: NodePort <4>
  ports:
  - name: http
    port: 80 <5>
    targetPort: http
  selector:
    app: jsonreader <6>
----
<1> Tipo de recurso a desplegar
<2> Nombre del servicio
<3> Namespace de despliegue
<4> Tipo de servivio. NodePort hará que el servicio esté disponible en la IP de los nodos en los que estén los pods y un puerto aleatorio entre 30000 y 32767
<5> Puerto en el que los pods están sirviendo su contenido
<6> Etiqueta que tiene que coincidir con la usada en el Deployment

El despliegue se realiza con `kubectl` con el comando siguiente

[source, bash]
----
$ kubectl create -f json-reader-service.yaml
----

El despliegue nos permitirá acceder a la aplicación en un puerto en el rango 30000-32767. En este caso ha tocado el 31976

[source, bash]
----
$ kubectl get services
NAME           TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
jsonproducer   NodePort    10.105.30.95   <none>        80:30228/TCP   2m37s
jsonreader     NodePort    10.99.85.2     <none>        80:31976/TCP   18s
kubernetes     ClusterIP   10.96.0.1      <none>        443/TCP        6m21s
----


Para poder acceder al servicio pediremos a Minikube que nos lo muestre.

[source, bash]
----
$ minikube service jsonreader
----

Esto hará que se abra un navegador con la aplicación `jsonreader` que simplemente lee el JSON y presenta un saludo sencillo.

image::KubernetesServiceReader.png[]

También podemos usar el Kubernetes Dashboard para mostrar información de interés sobre este despliegue, viendo como de Deployment de `jsonreader` se ha incorporado a la lista de despliegues disponibles en el cluster, así como los pods, ReplicaSets y servicios, como muestran las figuras siguientes.

image::KubernetesDashboardJSON1.png[]

image::KubernetesDashboardJSON2.png[]

## Apéndice. Cheat Sheet

### Comandos Minikube

* `minikube version`
* `minikube start`
* `minikube dashboard`
* `minikube service <nombre-servicio>`
* `minikube delete`


### Comandos `kubectl`

* `kubectl version`
* `kubectl cluster-info`
* `kubectl get nodes` 
* `kubectl run <deployment> --image=<image> --port=<container-port>`
* `kubectl expose deployment <deployment>> --type=NodePort`
* `kubectl get deployments` 
* `kubectl get services` 
* `kubectl describe pods|deployments|services <resource>`
* `kubectl scale deployments <deployment> --replicas=<number-of-replicas>`
* `kubectl delete pods|deployments|services <resource>`
* `kubectl set image deployments <deployment> <deployment>=<image>`
* `kubectl rollout undo deployments <deployment>`
* `kubectl logs <pod>`
* `kubectl exec <pod> <command>`